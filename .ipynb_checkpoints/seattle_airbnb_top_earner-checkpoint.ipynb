{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1689,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Bc3J0ttmpbJa"
   },
   "outputs": [],
   "source": [
    "# CMPS140 Project - How to Become Top Earner in Airbnb?\n",
    "# Tangni Wang, Tung Hoi Man, Yunxiang Fu\n",
    "# {twang63, tuman, yfu7}@ucsc.edu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1690,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tried:\n",
    "# dropna for new_score_reviews\n",
    "\n",
    "# To do:\n",
    "# Generate graph\n",
    "# Try StandardScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1691,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")\n",
    "\n",
    "import sklearn # sci-kit learn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error, median_absolute_error, mean_squared_log_error, explained_variance_score\n",
    "from sklearn.model_selection import cross_validate, cross_val_predict, cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1692,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions\n",
    "def correction(x):\n",
    "    '''\n",
    "    Columns value corrections\n",
    "    '''\n",
    "    if type(x)==str:\n",
    "        x=x.replace('$','')\n",
    "        x=x.replace(',','')\n",
    "        x=float(x)    \n",
    "    return (x)\n",
    "\n",
    "def correction2(x):\n",
    "    '''\n",
    "    Columns value corrections\n",
    "    '''\n",
    "    if type(x)==str:\n",
    "        x=x.replace('%','')\n",
    "        x=float(x)/100.0\n",
    "    return (x)\n",
    "\n",
    "def to_int(x):\n",
    "    '''\n",
    "    Columns value corrections\n",
    "    '''\n",
    "    if x=='f':\n",
    "        x=x.replace('f','0')\n",
    "    elif x=='t':\n",
    "        x=x.replace('t','1')\n",
    "    else:\n",
    "        x= '0'\n",
    "    return int(x)\n",
    "\n",
    "# def changeTime(x):\n",
    "#     '''\n",
    "#     change host_response_time columns from string into numerical.\n",
    "#     '''\n",
    "#     if x == 'within an hour':\n",
    "#         x=x.replace('within an hour', '1')\n",
    "#     elif x == 'within a few hours':\n",
    "#         x=x.replace('within a few hours', '4')\n",
    "#     elif x == 'within a day':\n",
    "#         x=x.replace('within a day', '24')\n",
    "#     elif x == 'a few days or more':\n",
    "#         x=x.replace('a few days or more', '48')\n",
    "#     else:\n",
    "#         x='96'\n",
    "        \n",
    "#     return int(x)\n",
    "\n",
    "def changeTime(x):\n",
    "    '''\n",
    "    change host_response_time columns from string into numerical.\n",
    "    '''\n",
    "    if x == 'within an hour':\n",
    "        x='1'\n",
    "    elif x == 'within a few hours':\n",
    "        x='4'\n",
    "    elif x == 'within a day':\n",
    "        x='24'\n",
    "    elif x == 'a few days or more':\n",
    "        x='48'\n",
    "    else:\n",
    "        x='96'\n",
    "        \n",
    "    return x\n",
    "\n",
    "def convertPolicy(x):\n",
    "    '''\n",
    "    Convert cancellation_policy columns from string into numerical.\n",
    "    '''\n",
    "    if x == 'strict':\n",
    "        x=x.replace('strict', '1')\n",
    "    elif x == 'moderate':\n",
    "        x=x.replace('moderate', '3')\n",
    "    elif x == 'flexible':\n",
    "        x=x.replace('flexible', '5')\n",
    "    else:\n",
    "        x='3'\n",
    "        \n",
    "    return int(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1693,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parsing csv file\n",
    "seattle_file_path = 'seattle_data/listings.csv'\n",
    "seattle_data = pd.read_csv(seattle_file_path)\n",
    "# seattle_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1694,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a new attribute for prediction\n",
    "seattle_data['new_score_reviews'] = seattle_data['reviews_per_month'] * seattle_data['review_scores_rating'] / 10\n",
    "# seattle_data.describe()\n",
    "# seattle_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1695,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The boundaries of top performer listings: 44.109\n",
      "The boundaries of low performer listings: 6.480000000000001\n"
     ]
    }
   ],
   "source": [
    "# Define top performers and low performers\n",
    "top90flag = seattle_data['new_score_reviews'].quantile(0.9)\n",
    "upto25flag = seattle_data['new_score_reviews'].quantile(0.25)\n",
    "\n",
    "seattle_data['top90'] = seattle_data.new_score_reviews >= top90flag\n",
    "seattle_data['upto25'] = seattle_data.new_score_reviews <= upto25flag\n",
    "\n",
    "print('The boundaries of top performer listings:', top90flag)\n",
    "print('The boundaries of low performer listings:', upto25flag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1696,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-1696-c4b674d057d7>, line 64)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-1696-c4b674d057d7>\"\u001b[0;36m, line \u001b[0;32m64\u001b[0m\n\u001b[0;31m    sklearn.preprocessing import StandardScaler\u001b[0m\n\u001b[0m                               ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# Data Processing\n",
    "\n",
    "# Drop useless columns\n",
    "useless_colmuns = ['id', 'listing_url', 'scrape_id', 'last_scraped', 'name', 'summary', 'space', 'description',\n",
    "    'experiences_offered', 'neighborhood_overview', 'notes', 'transit', 'thumbnail_url', 'medium_url', 'picture_url',\n",
    "    'xl_picture_url', 'host_id', 'host_url', 'host_name', 'host_since', 'host_location', 'host_about',\n",
    "    'host_response_rate', 'host_acceptance_rate', 'host_thumbnail_url', 'host_picture_url', 'host_neighbourhood',\n",
    "    'host_listings_count', 'host_total_listings_count', 'host_verifications', 'host_has_profile_pic', 'street', \n",
    "    'neighbourhood', 'neighbourhood_cleansed', 'neighbourhood_group_cleansed', 'city', 'state', 'market',\n",
    "    'smart_location', 'country_code', 'country', 'latitude', 'longitude', 'is_location_exact', 'property_type', \n",
    "    'room_type', 'bed_type', 'amenities', 'square_feet', 'guests_included', 'maximum_nights', 'calendar_updated', \n",
    "    'has_availability', 'availability_30', 'availability_60', 'availability_90', 'availability_365', \n",
    "    'calendar_last_scraped', 'number_of_reviews', 'first_review', 'last_review', 'review_scores_accuracy', \n",
    "    'review_scores_cleanliness', 'review_scores_checkin', 'review_scores_communication', 'review_scores_location', \n",
    "    'review_scores_value', 'requires_license', 'license', 'jurisdiction_names', 'require_guest_profile_picture', \n",
    "    'require_guest_phone_verification', 'calculated_host_listings_count', 'review_scores_rating', 'reviews_per_month'\n",
    "]\n",
    "seattle_data.drop(useless_colmuns, axis=1)\n",
    "\n",
    "# Remove $: price, weekly_price, security_deposit, extra_people, cleaning_fee\n",
    "seattle_data['price']=seattle_data['price'].map(lambda x: correction(x))\n",
    "seattle_data['weekly_price'] = seattle_data['weekly_price'].map(lambda x: correction(x))\n",
    "seattle_data['monthly_price'] = seattle_data['monthly_price'].map(lambda x: correction(x))\n",
    "seattle_data['security_deposit'] = seattle_data['security_deposit'].map(lambda x: correction(x))\n",
    "seattle_data['extra_people'] = seattle_data['extra_people'].map(lambda x: correction(x))\n",
    "seattle_data['cleaning_fee'] = seattle_data['cleaning_fee'].map(lambda x: correction(x))\n",
    "\n",
    "# Convert string to number: host_response_time, cancellation_policy\n",
    "seattle_data['host_response_time'] = seattle_data['host_response_time'].apply(changeTime).astype(int)\n",
    "seattle_data['cancellation_policy'] = seattle_data['cancellation_policy'].map(lambda x: convertPolicy(x))\n",
    "\n",
    "# Convert boolean t/f to int 1/0: host_is_superhost, host_identity_verified, instant_bookable\n",
    "for i in seattle_data.columns:\n",
    "    \n",
    "    if set(seattle_data[i])=={'t','f'}:\n",
    "        seattle_data[i]=seattle_data[i].apply(to_int)\n",
    "        \n",
    "    elif set(seattle_data[i]) == {'t','f',np.nan}:\n",
    "        seattle_data[i]=seattle_data[i].apply(to_int)\n",
    "\n",
    "# Fill missing value with reasonable values like 0 or 1.\n",
    "seattle_data['new_score_reviews'].fillna(0, inplace = True)\n",
    "seattle_data['accommodates'].fillna(0, inplace = True)\n",
    "seattle_data['bathrooms'].fillna(0, inplace = True)\n",
    "seattle_data['beds'].fillna(0, inplace = True)\n",
    "seattle_data['price'].fillna(0, inplace = True)\n",
    "seattle_data['weekly_price'].fillna(0, inplace = True)\n",
    "seattle_data['monthly_price'].fillna(0, inplace = True)\n",
    "seattle_data['security_deposit'].fillna(0, inplace = True)\n",
    "seattle_data['cleaning_fee'].fillna(0, inplace = True)\n",
    "seattle_data['extra_people'].fillna(0, inplace = True)\n",
    "seattle_data['minimum_nights'].fillna(1, inplace = True)\n",
    "\n",
    "# Relevant Features\n",
    "seattle_features = ['zipcode', 'accommodates', 'bathrooms', 'bedrooms', 'beds', 'price', 'weekly_price', \n",
    "                    'monthly_price', 'security_deposit', 'cleaning_fee', 'extra_people', 'minimum_nights', \n",
    "                    'host_response_time', 'host_is_superhost', 'host_identity_verified', 'instant_bookable', \n",
    "                    'cancellation_policy', 'new_score_reviews' \n",
    "                    ]\n",
    "\n",
    "# Drop rows if any feature still has missing value\n",
    "seattle_data = seattle_data[seattle_features].dropna()\n",
    "\n",
    "scaler = StandardScaler()\n",
    "print(scaler.fit(seattle_data))\n",
    "StandardScaler(copy=True, with_mean=True, with_std=True)\n",
    "print(scaler.mean_)\n",
    "print(scaler.transform(seattle_data))\n",
    "\n",
    "# print(seattle_data[seattle_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Needed features:\n",
    "# X is the independent variable\n",
    "\n",
    "# Strong, weak, no corr attributes\n",
    "features = ['zipcode', 'accommodates', 'bathrooms', 'bedrooms', 'beds', 'price', 'weekly_price', \n",
    "                    'monthly_price', 'security_deposit', 'cleaning_fee', 'extra_people', 'minimum_nights', \n",
    "                    'host_response_time', 'host_is_superhost', 'host_identity_verified', 'instant_bookable', \n",
    "                    'cancellation_policy'\n",
    "            ]\n",
    "'''\n",
    "Results:\n",
    "lin_model score: 0.3223501586770844\n",
    "lin_model mae: 10.661385130886293\n",
    "\n",
    "rfr_model score: 0.3677538939581594\n",
    "rfr_model mae: 9.986079432324608\n",
    "'''\n",
    "\n",
    "# Strong, weak corr attributes\n",
    "# features = ['accommodates', 'bathrooms', 'bedrooms', 'beds', 'price', 'cleaning_fee', 'host_response_time',\n",
    "#             'host_is_superhost', 'host_identity_verified', 'instant_bookable'  \n",
    "#             ]\n",
    "'''\n",
    "Results:\n",
    "lin_model score: 0.32954309458973907\n",
    "lin_model mae: 10.606657878897977\n",
    "\n",
    "rfr_model score: 0.2638499447071493\n",
    "rfr_model mae: 11.006618243728004\n",
    "'''\n",
    "\n",
    "# Strong corr attributes\n",
    "# features = ['bedrooms', 'price', 'cleaning_fee', 'host_response_time', 'host_is_superhost', 'instant_bookable'  \n",
    "#             ]\n",
    "'''\n",
    "Results:\n",
    "lin_model score: 0.3133239990486608\n",
    "lin_model mae: 10.784478109787775\n",
    "\n",
    "rfr_model score: 0.22763549901183178\n",
    "rfr_model mae: 11.0913438807328\n",
    "'''\n",
    "\n",
    "    \n",
    "X = seattle_data[features]\n",
    "# Statistic of seattle features\n",
    "# X\n",
    "X.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Prediction target, dependent variable\n",
    "y = seattle_data.new_score_reviews\n",
    "# y\n",
    "y.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "The pairs plot builds on two basic figures, the histogram and the scatter plot. \n",
    "The histogram on the diagonal allows us to see the distribution of a single variable \n",
    "while the scatter plots on the upper and lower triangles show the relationship (or lack thereof) \n",
    "between two variables.\n",
    "'''\n",
    "# sns.pairplot(seattle_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "A histogram divides the variable into bins, counts the data points in each bin, \n",
    "and shows the bins on the x-axis and the counts on the y-axis.\n",
    "'''\n",
    "sns.distplot(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Correlation\n",
    "'''\n",
    "The correlation coefficient, or simply the correlation, is an index that ranges from -1 to 1. \n",
    "When the value is near zero, there is no linear relationship. \n",
    "As the correlation gets closer to plus or minus one, the relationship is stronger. \n",
    "A value of one (or negative one) indicates a perfect linear relationship between two variables.\n",
    "'''\n",
    "\n",
    "# result: \n",
    "# stronger correlation: host_is_superhost, instant_bookable, host_response_time, bedrooms, price, cleaning fee\n",
    "# weaker corr: accommodates, beds, bathrooms, host_identity_verified, \n",
    "# almost no corr: zipcode, weekly_price, monthly_price, security_deposit, extra_people, cancellation_policy, minimum_nights\n",
    "\n",
    "# seattle_data.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Split training and testing set. Training = 80%. Testing = 20%\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Baseline model\n",
    "# Make prediction by mean and median\n",
    "# Best possible score is 1.0 and it can be negative (because the model can be arbitrarily worse).\n",
    "\n",
    "from sklearn.dummy import DummyRegressor\n",
    "# from sklearn.metrics import r2_score\n",
    "\n",
    "# Create a dummy regressor\n",
    "baseline_model = DummyRegressor(strategy='median')\n",
    "\n",
    "# \"Train\" dummy regressor\n",
    "baseline_model.fit(X_train, y_train)\n",
    "# print(dummy_mean)\n",
    "\n",
    "# Predict\n",
    "# print(\"Baseline model predicitions using testing set \")\n",
    "# print(X2.head())\n",
    "# print(\"The predictions are:\")\n",
    "y_pred_bm = baseline_model.predict(X_test)\n",
    "# print(y_pred_bm)\n",
    "# print(\"The score is:\")\n",
    "# print(baseline_model.score(X_test, y_test))\n",
    "\n",
    "print(\"rfr_model r2_score:\", r2_score(y_test, y_pred_bm))\n",
    "print(\"rfr_model ev_score:\", explained_variance_score(y_test, y_pred_bm))\n",
    "print(\"rfr_model mae:\", mean_absolute_error(y_pred_bm, y_test))\n",
    "print(\"rfr_model mse:\", mean_squared_error(y_pred_bm, y_test))\n",
    "print(\"rfr_model med_ae:\", median_absolute_error(y_pred_bm, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Linear Regression, stretch model?\n",
    "lin_model = linear_model.LinearRegression()\n",
    "lin_model = lin_model.fit(X_train, y_train)\n",
    "y_pred_lm = lin_model.predict(X_test)\n",
    "# print(y_pred_lm)\n",
    "\n",
    "plt.scatter(y_test, y_pred_lm)\n",
    "plt.xlabel(\"True Values (y_test)\")\n",
    "plt.ylabel(\"Predictions (y_pred_lm)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.regplot(x=y_test, y=y_pred_lm);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"lin_model score:\", lin_model.score(X_test, y_test))\n",
    "print(\"lin_model r2_score:\", r2_score(y_test, y_pred_lm))\n",
    "print(\"lin_model ev_score:\", explained_variance_score(y_test, y_pred_lm))\n",
    "print(\"lin_model mae:\", mean_absolute_error(y_pred_lm, y_test))\n",
    "print(\"lin_model mse:\", mean_squared_error(y_pred_lm, y_test))\n",
    "print(\"lin_model med_ae:\", median_absolute_error(y_pred_lm, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# The coefficients\n",
    "print('Coefficients: \\n', lin_model.coef_)\n",
    "# The mean squared error (mse)\n",
    "print(\"Mean squared error: %.2f\"\n",
    "      % mean_squared_error(y_test, y_pred))\n",
    "# Explained variance score: 1 is perfect prediction, same as score\n",
    "print('Variance score (same as score): %.3f' % r2_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ridge Regression with built-in cross-validation of the alpha parameter.\n",
    "ridgecv_model = linear_model.RidgeCV(alphas=[0.1, 1.0, 10.0], cv=6, fit_intercept=True, scoring=None,\n",
    "    normalize=False)\n",
    "ridgecv_model.fit(X_train, y_train)\n",
    "# ridgecv_model.alpha_\n",
    "y_pred_rcv = ridgecv_model.predict(X_test)\n",
    "# print(y_pred_rcv)\n",
    "\n",
    "plt.scatter(y_test, y_pred_rcv)\n",
    "plt.xlabel(\"True Values (y_test)\")\n",
    "plt.ylabel(\"Predictions (y_pred_rcv)\")\n",
    "\n",
    "# print(\"ridgecv_model score:\", ridgecv_model.score(X_test, y_test))\n",
    "print(\"ridgecv_model r2_score:\", r2_score(y_test, y_pred_rcv))\n",
    "print(\"ridgecv_model ev_score:\", explained_variance_score(y_test, y_pred_rcv))\n",
    "print(\"ridgecv_model mae:\", mean_absolute_error(y_pred_rcv, y_test))\n",
    "print(\"ridgecv_model mse:\", mean_squared_error(y_pred_rcv, y_test))\n",
    "print(\"ridgecv_model med_ae:\", median_absolute_error(y_pred_rcv, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Ridge Regression\n",
    "ridge_model = linear_model.Ridge(alpha=.5, copy_X=True, fit_intercept=True, max_iter=None,\n",
    "      normalize=False, random_state=None, solver='auto', tol=0.001)\n",
    "ridge_model.fit(X_train, y_train)\n",
    "# reg.coef_\n",
    "# reg.intercept_\n",
    "y_pred_ridge = ridge_model.predict(X_test)\n",
    "# print(y_pred_ridge)\n",
    "\n",
    "plt.scatter(y_test, y_pred_ridge)\n",
    "plt.xlabel(\"True Values (y_test)\")\n",
    "plt.ylabel(\"Predictions (y_pred_ridge)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.regplot(x=y_test, y=y_pred_ridge);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"ridge_model score:\", ridge_model.score(X_test, y_test))\n",
    "print(\"ridge_model r2_score:\", r2_score(y_test, y_pred_ridge))\n",
    "print(\"ridge_model ev_score:\", explained_variance_score(y_test, y_pred_ridge))\n",
    "print(\"ridge_model mae:\", mean_absolute_error(y_pred_ridge, y_test))\n",
    "print(\"ridge_model mse:\", mean_squared_error(y_pred_ridge, y_test))\n",
    "print(\"ridge_model med_ae:\", median_absolute_error(y_pred_ridge, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform 9-fold cross validation (cv)\n",
    "\n",
    "scores = cross_val_score(lin_model, X, y, cv=9)\n",
    "print(\"Cross-validated scores:\", scores)                                         \n",
    "\n",
    "# As you can see, the last fold improved the score of the original model — from 0.322 to 0.392\n",
    "\n",
    "# Make cross validated predictions\n",
    "y_pred_cvp = cross_val_predict(lin_model, X_test, y_test, cv=9)\n",
    "# print(y_pred_cvp)\n",
    "plt.scatter(y_test, y_pred_cvp)\n",
    "\n",
    "# Cross-Predicted Accuracy, r2_score\n",
    "# accuracy = metrics.r2_score(y_test, y_pred_cvp)\n",
    "# print(\"Cross-Predicted Accuracy:\", accuracy)\n",
    "\n",
    "# print(\"cross_val_predict mae:\", mean_absolute_error(y_pred_cvp, y_test))\n",
    "print(\"cross_val_predict r2_score:\", r2_score(y_test, y_pred_cvp))\n",
    "print(\"cross_val_predict ev_score:\", explained_variance_score(y_test, y_pred_cvp))\n",
    "print(\"cross_val_predict mae:\", mean_absolute_error(y_pred_cvp, y_test))\n",
    "print(\"cross_val_predict mse:\", mean_squared_error(y_pred_cvp, y_test))\n",
    "print(\"cross_val_predict med_ae:\", median_absolute_error(y_pred_cvp, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lasso Regression\n",
    "lasso_model = linear_model.Lasso(alpha=0.1, copy_X=True, fit_intercept=True, max_iter=1000,\n",
    "   normalize=False, positive=False, precompute=False, random_state=None,\n",
    "   selection='cyclic', tol=0.0001, warm_start=False)\n",
    "\n",
    "lasso_model.fit(X_train, y_train)\n",
    "y_pred_lasso = lasso_model.predict(X_test)\n",
    "\n",
    "plt.scatter(y_test, y_pred_lasso)\n",
    "plt.xlabel(\"True Values (y_test)\")\n",
    "plt.ylabel(\"Predictions (y_pred_lasso)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"lasso_model score:\", lasso_model.score(X_test, y_test))\n",
    "\n",
    "print(\"lasso_model r2_score:\", r2_score(y_test, y_pred_lasso))\n",
    "print(\"lasso_model ev_score:\", explained_variance_score(y_test, y_pred_lasso))\n",
    "print(\"lasso_model mae:\", mean_absolute_error(y_pred_lasso, y_test))\n",
    "print(\"lasso_model mse:\", mean_squared_error(y_pred_lasso, y_test))\n",
    "print(\"lasso_model med_ae:\", median_absolute_error(y_pred_lasso, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DecisionTreeRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "dtr_model = DecisionTreeRegressor()\n",
    "dtr_model = dtr_model.fit(X_train, y_train)\n",
    "y_pred_dtr = dtr_model.predict(X_test)\n",
    "\n",
    "plt.scatter(y_test, y_pred_dtr)\n",
    "plt.xlabel(\"True Values (y_test)\")\n",
    "plt.ylabel(\"Predictions (y_pred_dtr)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.regplot(x=y_test, y=y_pred_dtr);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"dtr_model score:\", dtr_model.score(X_test, y_test))\n",
    "\n",
    "print(\"dtr_model r2_score:\", r2_score(y_test, y_pred_dtr))\n",
    "print(\"dtr_model ev_score:\", explained_variance_score(y_test, y_pred_dtr))\n",
    "print(\"dtr_model mae:\", mean_absolute_error(y_pred_dtr, y_test))\n",
    "print(\"dtr_model mse:\", mean_squared_error(y_pred_dtr, y_test))\n",
    "print(\"dtr_model med_ae:\", median_absolute_error(y_pred_dtr, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# RandomForestRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.datasets import make_regression\n",
    "\n",
    "# X, y = make_regression(n_features=17, n_informative=2, random_state=0, shuffle=False)\n",
    "# rfr_model = RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=2,\n",
    "#            max_features='auto', max_leaf_nodes=None,\n",
    "#            min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "#            min_samples_leaf=1, min_samples_split=2,\n",
    "#            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=None,\n",
    "#            oob_score=False, random_state=0, verbose=0, warm_start=False)\n",
    "\n",
    "rfr_model = RandomForestRegressor(random_state=1)\n",
    "rfr_model.fit(X_train, y_train)\n",
    "y_pred_rfr = rfr_model.predict(X_test)\n",
    "\n",
    "print(rfr_model.feature_importances_)\n",
    "# print(y_pred_rfr)\n",
    "\n",
    "plt.scatter(y_test, y_pred_rfr)\n",
    "plt.xlabel(\"True Values (y_test)\")\n",
    "plt.ylabel(\"Predictions (y_pred_rfr)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.regplot(x=y_test, y=y_pred_rfr);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# score = r2_score: 0-1, 1 is the best\n",
    "# Best possible score is 1.0 and it can be negative (because the model can be arbitrarily worse). \n",
    "# A constant model that always predicts the expected value of y, disregarding the input features, would get a R^2 score of 0.0.\n",
    "# mean_ae: MAE output is non-negative floating point. The best value is 0.0\n",
    "# mse: A non-negative floating point value (the best value is 0.0)\n",
    "# msle: A non-negative floating point value (the best value is 0.0)\n",
    "# median_ae: A positive floating point value (the best value is 0.0)\n",
    "\n",
    "# print(\"rfr_model score:\", rfr_model.score(X_test, y_test))\n",
    "print(\"rfr_model r2_score:\", r2_score(y_test, y_pred_rfr))\n",
    "print(\"rfr_model ev_score:\", explained_variance_score(y_test, y_pred_rfr))\n",
    "print(\"rfr_model mae:\", mean_absolute_error(y_pred_rfr, y_test))\n",
    "print(\"rfr_model mse:\", mean_squared_error(y_pred_rfr, y_test))\n",
    "# print(\"rfr_model msle:\", mean_squared_log_error(y_pred_rfr, y_test))\n",
    "print(\"rfr_model med_ae:\", median_absolute_error(y_pred_rfr, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What attributes affect earning? Assume new_score_reviews proportional to earning.\n",
    "'''\n",
    "The boundaries of top performer listings: 44.109\n",
    "The boundaries of low performer listings: 6.480000000000001\n",
    "Extract rows that is top performer -> list\n",
    "Extract rows that is low performer -> list\n",
    "Compare attributes, analyze the correlation? Then decide which attributes has causal effect to new_score_reviews.\n",
    "\n",
    "'''\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "CMPS140 Project.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
